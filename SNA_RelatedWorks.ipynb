{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f0b74bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thanos/Documents/leiden/S1/SNA/SNA-14B/core_periphery_sbm/core_periphery.py:344: SyntaxWarning: invalid escape sequence '\\m'\n",
      "  \"\"\"\n",
      "/home/thanos/Documents/leiden/S1/SNA/SNA-14B/core_periphery_sbm/core_periphery.py:415: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  \"\"\"\n",
      "/home/thanos/Documents/leiden/S1/SNA/SNA-14B/core_periphery_sbm/core_periphery.py:550: SyntaxWarning: invalid escape sequence '\\m'\n",
      "  \"\"\"\n",
      "/home/thanos/Documents/leiden/S1/SNA/SNA-14B/core_periphery_sbm/core_periphery.py:743: SyntaxWarning: invalid escape sequence '\\m'\n",
      "  \"\"\"\n",
      "/home/thanos/Documents/leiden/S1/SNA/SNA-14B/core_periphery_sbm/inference.py:63: SyntaxWarning: invalid escape sequence '\\m'\n",
      "  \"\"\"\n",
      "/home/thanos/Documents/leiden/S1/SNA/SNA-14B/core_periphery_sbm/inference.py:284: SyntaxWarning: invalid escape sequence '\\m'\n",
      "  \"\"\"\n",
      "/home/thanos/Documents/leiden/S1/SNA/SNA-14B/core_periphery_sbm/inference.py:308: SyntaxWarning: invalid escape sequence '\\m'\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------GALLAGHER'S METHOD---------\n",
      "Node to probabilities (HubSpoke): {0: array([0.26, 0.74]), 1: array([0.82, 0.18]), 2: array([0.27, 0.73]), 3: array([0.26, 0.74]), 4: array([0.26, 0.74]), 5: array([0.28, 0.72]), 6: array([0.18, 0.82]), 7: array([0.36, 0.64]), 8: array([0.32, 0.68]), 9: array([0.53, 0.47]), 10: array([0.36, 0.64]), 11: array([0.88, 0.12]), 12: array([0.4, 0.6]), 13: array([0.38, 0.62]), 14: array([0.26, 0.74]), 15: array([0.54, 0.46]), 16: array([0.27, 0.73]), 17: array([0.66, 0.34]), 18: array([0.35, 0.65]), 19: array([0.25, 0.75]), 20: array([0.25, 0.75]), 21: array([0.27, 0.73]), 22: array([0.35, 0.65]), 23: array([0.28, 0.72]), 24: array([0.87, 0.13]), 25: array([0.29, 0.71]), 26: array([0.45, 0.55]), 27: array([0.43, 0.57]), 28: array([0.52, 0.48]), 29: array([0.72, 0.28]), 30: array([0.75, 0.25]), 31: array([0.86, 0.14]), 32: array([0.21, 0.79]), 33: array([0.25, 0.75]), 34: array([0.28, 0.72]), 35: array([0.8, 0.2]), 36: array([0.57, 0.43]), 37: array([0.39, 0.61]), 38: array([0.61, 0.39]), 39: array([0.7, 0.3]), 40: array([0.7, 0.3]), 41: array([0.5, 0.5]), 42: array([0.34, 0.66]), 43: array([0.85, 0.15]), 44: array([0.83, 0.17]), 45: array([0.27, 0.73]), 46: array([0.28, 0.72]), 47: array([0.7, 0.3]), 48: array([0.73, 0.27]), 49: array([0.33, 0.67]), 50: array([0.47, 0.53]), 51: array([0.47, 0.53]), 52: array([0.32, 0.68]), 53: array([0.59, 0.41]), 54: array([0.24, 0.76]), 55: array([0.38, 0.62]), 56: array([0.51, 0.49]), 57: array([0.23, 0.77]), 58: array([0.31, 0.69]), 59: array([0.35, 0.65]), 60: array([0.32, 0.68]), 61: array([0.23, 0.77])}\n",
      "Core Nodes (HubSpoke): [1, 9, 11, 15, 17, 24, 28, 29, 30, 31, 35, 36, 38, 39, 40, 41, 43, 44, 47, 48, 53, 56]\n",
      "Periphery Nodes (HubSpoke): [0, 2, 3, 4, 5, 6, 7, 8, 10, 12, 13, 14, 16, 18, 19, 20, 21, 22, 23, 25, 26, 27, 32, 33, 34, 37, 42, 45, 46, 49, 50, 51, 52, 54, 55, 57, 58, 59, 60, 61]\n",
      "Node to probabilities (Layered): [[0.19 0.28 0.53]\n",
      " [0.42 0.44 0.14]\n",
      " [0.14 0.32 0.54]\n",
      " [0.16 0.31 0.53]\n",
      " [0.16 0.38 0.46]\n",
      " [0.21 0.35 0.44]\n",
      " [0.16 0.23 0.61]\n",
      " [0.16 0.4  0.44]\n",
      " [0.18 0.29 0.53]\n",
      " [0.17 0.52 0.31]\n",
      " [0.1  0.33 0.57]\n",
      " [0.71 0.25 0.04]\n",
      " [0.26 0.35 0.39]\n",
      " [0.27 0.36 0.37]\n",
      " [0.17 0.28 0.55]\n",
      " [0.36 0.37 0.27]\n",
      " [0.17 0.36 0.47]\n",
      " [0.41 0.31 0.28]\n",
      " [0.2  0.33 0.47]\n",
      " [0.15 0.3  0.55]\n",
      " [0.16 0.3  0.54]\n",
      " [0.18 0.26 0.56]\n",
      " [0.19 0.33 0.48]\n",
      " [0.12 0.22 0.66]\n",
      " [0.51 0.32 0.17]\n",
      " [0.15 0.35 0.5 ]\n",
      " [0.25 0.46 0.29]\n",
      " [0.28 0.38 0.34]\n",
      " [0.4  0.35 0.25]\n",
      " [0.49 0.31 0.2 ]\n",
      " [0.55 0.31 0.14]\n",
      " [0.67 0.25 0.08]\n",
      " [0.12 0.21 0.67]\n",
      " [0.12 0.35 0.53]\n",
      " [0.31 0.3  0.39]\n",
      " [0.5  0.32 0.18]\n",
      " [0.32 0.39 0.29]\n",
      " [0.26 0.31 0.43]\n",
      " [0.44 0.3  0.26]\n",
      " [0.42 0.35 0.23]\n",
      " [0.5  0.35 0.15]\n",
      " [0.38 0.35 0.27]\n",
      " [0.29 0.36 0.35]\n",
      " [0.54 0.36 0.1 ]\n",
      " [0.43 0.35 0.22]\n",
      " [0.17 0.38 0.45]\n",
      " [0.11 0.31 0.58]\n",
      " [0.43 0.35 0.22]\n",
      " [0.37 0.35 0.28]\n",
      " [0.2  0.29 0.51]\n",
      " [0.26 0.36 0.38]\n",
      " [0.28 0.38 0.34]\n",
      " [0.19 0.34 0.47]\n",
      " [0.28 0.39 0.33]\n",
      " [0.16 0.37 0.47]\n",
      " [0.23 0.37 0.4 ]\n",
      " [0.28 0.46 0.26]\n",
      " [0.13 0.33 0.54]\n",
      " [0.18 0.29 0.53]\n",
      " [0.16 0.37 0.47]\n",
      " [0.19 0.32 0.49]\n",
      " [0.2  0.25 0.55]]\n",
      "Number of layers detected in the Layered structure: 3\n",
      "Core Nodes (Layer 1): [11, 17, 24, 28, 29, 30, 31, 35, 38, 39, 40, 41, 43, 44, 47, 48]\n",
      "Periphery Nodes (Layer 2): [1, 9, 15, 26, 27, 36, 42, 51, 53, 56]\n",
      "Periphery Nodes (Layer 3): [0, 2, 3, 4, 5, 6, 7, 8, 10, 12, 13, 14, 16, 18, 19, 20, 21, 22, 23, 25, 32, 33, 34, 37, 45, 46, 49, 50, 52, 54, 55, 57, 58, 59, 60, 61]\n",
      "P(A | k, g) for Hub-and-Spoke Structure: 1.476116165018295e-95\n",
      "P(A | k, g) for Layered Structure: 5.08561610357407e-72\n",
      "Layered structure is more suitable for this network.\n",
      "----------------------------------------------\n",
      "---------BOGATTI AND EVERETT'S METHOD---------\n",
      "Median Coreness Threshold: 0.035322293846323634\n",
      "Node Coreness Values: {0: np.float64(0.0), 1: np.float64(0.0748403932261503), 2: np.float64(0.0), 3: np.float64(0.0), 4: np.float64(0.0), 5: np.float64(0.0), 6: np.float64(0.0), 7: np.float64(0.0), 8: np.float64(0.0), 9: np.float64(0.0), 10: np.float64(0.0), 11: np.float64(0.9943605262808801), 12: np.float64(0.0), 13: np.float64(0.1276004340936295), 14: np.float64(0.0), 15: np.float64(0.12760405243800443), 16: np.float64(0.0), 17: np.float64(0.0), 18: np.float64(0.0), 19: np.float64(0.0), 20: np.float64(0.0), 21: np.float64(0.0), 22: np.float64(0.0), 23: np.float64(0.0), 24: np.float64(0.45886054179153524), 25: np.float64(0.047951345512845724), 26: np.float64(0.3008295164269585), 27: np.float64(0.2949740619118988), 28: np.float64(0.3559537306094726), 29: np.float64(0.4513790903053483), 30: np.float64(0.4941793187971353), 31: np.float64(0.9668543590485278), 32: np.float64(0.07484663295530974), 33: np.float64(0.07481081415294856), 34: np.float64(0.26999496867623435), 35: np.float64(0.40822506262694264), 36: np.float64(0.29520982077956204), 37: np.float64(0.23984295590960025), 38: np.float64(0.37507176065852726), 39: np.float64(0.37852945417689304), 40: np.float64(0.4743028349550177), 41: np.float64(0.3052153782287222), 42: np.float64(0.14894367555884008), 43: np.float64(0.4483062644544783), 44: np.float64(0.19577323876988706), 45: np.float64(0.022693242179801544), 46: np.float64(0.0), 47: np.float64(0.29258038728343005), 48: np.float64(0.12970664197825096), 49: np.float64(0.009020806785237931), 50: np.float64(0.021042587800148976), 51: np.float64(0.11766372930604282), 52: np.float64(0.05150378402665187), 53: np.float64(0.01887710345650741), 54: np.float64(0.0005563296340800577), 55: np.float64(0.07706761585254743), 56: np.float64(0.07710054976313395), 57: np.float64(0.018341480887197798), 58: np.float64(0.018285107504072452), 59: np.float64(0.0), 60: np.float64(0.0), 61: np.float64(0.0)}\n",
      "Core Nodes: [1, 11, 13, 15, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 47, 48, 51, 52, 55, 56]\n",
      "Periphery Nodes: [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 14, 16, 17, 18, 19, 20, 21, 22, 23, 45, 46, 49, 50, 53, 54, 57, 58, 59, 60, 61]\n",
      "P(A | k, g) for Borgatti-Everett Method: 1.906086423743822e-28\n"
     ]
    }
   ],
   "source": [
    "import graph_tool.all as gt\n",
    "import networkx as nx\n",
    "import sys\n",
    "from itertools import combinations\n",
    "import math\n",
    "import numpy as np\n",
    "from core_periphery_sbm import core_periphery as cp\n",
    "\n",
    "\n",
    "# Convert a graph-tool graph to a NetworkX graph\n",
    "def graph_tool_to_networkx(gt_graph):\n",
    "    nx_graph = nx.Graph() if not gt_graph.is_directed() else nx.DiGraph()\n",
    "\n",
    "    # Add nodes\n",
    "    for v in gt_graph.vertices():\n",
    "        nx_graph.add_node(int(v))\n",
    "\n",
    "    # Add edges\n",
    "    for e in gt_graph.edges():\n",
    "        nx_graph.add_edge(int(e.source()), int(e.target()))\n",
    "\n",
    "    return nx_graph\n",
    "\n",
    "# Load Les Mis graph from NetworkX\n",
    "G = graph_tool_to_networkx(gt.collection.ns[\"terrorists_911\"])\n",
    "\n",
    "print(\"---------GALLAGHER'S METHOD---------\")\n",
    "# Initialize and infer Hub-and-Spoke model\n",
    "hubspoke = cp.HubSpokeCorePeriphery(n_gibbs=100, n_mcmc=100)  # Using a fixed number of MCMC steps for the whole graph\n",
    "hubspoke.infer(G)\n",
    "\n",
    "# Initialize and infer Layered model\n",
    "layered = cp.LayeredCorePeriphery(n_layers=3, n_gibbs=100, n_mcmc=100)  # Using a fixed number of MCMC steps for the whole graph\n",
    "layered.infer(G)\n",
    "\n",
    "# Get node-to-group assignments for both models\n",
    "node2label_hs = hubspoke.get_labels(prob=False, return_dict=True)\n",
    "node2label_l = layered.get_labels(prob=False, return_dict=True)\n",
    "\n",
    "# Calculate P(A | k, g)\n",
    "def calculate_p_a_k_g(graph, node2label):\n",
    "    \"\"\"\n",
    "    Calculate P(A | k, g) for a graph and node-to-layer mapping.\n",
    "\n",
    "    Args:\n",
    "        graph (nx.Graph): The input graph (NetworkX format).\n",
    "        node2label (dict): Mapping of nodes to their layer assignments.\n",
    "\n",
    "    Returns:\n",
    "        float: The value of P(A | k, g).\n",
    "    \"\"\"\n",
    "    # Number of layers (k)\n",
    "    k = len(set(node2label.values()))\n",
    "\n",
    "    # Initialize m_r and t_r for each group\n",
    "    m = [0] * k  # Number of edges within each group\n",
    "    t = [0] * k  # Number of possible pairs within each group\n",
    "\n",
    "    # Reverse the node-to-layer mapping to group nodes by layers\n",
    "    layer_to_nodes = {r: [] for r in range(k)}\n",
    "    for node, layer in node2label.items():\n",
    "        layer_to_nodes[layer].append(node)\n",
    "\n",
    "    # Calculate m_r and t_r for each group\n",
    "    for r in range(k):\n",
    "        nodes_in_layer = layer_to_nodes[r]\n",
    "        if len(nodes_in_layer) < 2:\n",
    "            continue  # Skip groups with fewer than 2 nodes\n",
    "\n",
    "        # Count edges within the group\n",
    "        m[r] = sum(1 for u, v in combinations(nodes_in_layer, 2) if graph.has_edge(u, v))\n",
    "\n",
    "        # Count total possible pairs within the group\n",
    "        t[r] = len(nodes_in_layer) * (len(nodes_in_layer) - 1) // 2\n",
    "\n",
    "    # Calculate P(A | k, g) using the formula\n",
    "    p_a_k_g = 1.0\n",
    "    for r in range(k):\n",
    "        if t[r] > 0:  # Avoid division by zero for empty groups\n",
    "            p_a_k_g *= (math.factorial(m[r]) * math.factorial(t[r] - m[r])) / math.factorial(t[r] + 1)\n",
    "\n",
    "    return p_a_k_g\n",
    "\n",
    "# Print probabilities for Hub-and-Spoke model\n",
    "node2probs_hs = hubspoke.get_labels(prob=True, return_dict=True)\n",
    "print(\"Node to probabilities (HubSpoke):\", node2probs_hs)\n",
    "\n",
    "# Print core and periphery nodes for Hub-and-Spoke model\n",
    "core_nodes_hs = [node for node, group in node2label_hs.items() if group == 0]  # Assuming core is group 0\n",
    "periphery_nodes_hs = [node for node, group in node2label_hs.items() if group != 0]\n",
    "print(\"Core Nodes (HubSpoke):\", core_nodes_hs)\n",
    "print(\"Periphery Nodes (HubSpoke):\", periphery_nodes_hs)\n",
    "\n",
    "# Print probabilities for Layered model\n",
    "node2probs_l = layered.get_labels(prob=True, return_dict=False)\n",
    "print(\"Node to probabilities (Layered):\", node2probs_l)\n",
    "\n",
    "# Count and print number of layers detected in the Layered model\n",
    "num_layers = len(set(node2label_l.values()))\n",
    "print(f\"Number of layers detected in the Layered structure: {num_layers}\")\n",
    "\n",
    "# Identify core and periphery nodes in the Layered model\n",
    "layer_to_nodes = {layer: [] for layer in range(num_layers)}\n",
    "for node, layer in node2label_l.items():\n",
    "    layer_to_nodes[layer].append(node)\n",
    "\n",
    "# Print core and periphery nodes for Layered model with layer numbers\n",
    "for layer, nodes in layer_to_nodes.items():\n",
    "    if layer == 0:\n",
    "        print(f\"Core Nodes (Layer {layer + 1}):\", nodes)\n",
    "    else:\n",
    "        print(f\"Periphery Nodes (Layer {layer + 1}):\", nodes)\n",
    "\n",
    "# Calculate P(A | k, g) for Hub-and-Spoke structure\n",
    "p_a_k_g_hs = calculate_p_a_k_g(G, node2label_hs)\n",
    "print(\"P(A | k, g) for Hub-and-Spoke Structure:\", p_a_k_g_hs)\n",
    "\n",
    "# Calculate P(A | k, g) for Layered structure\n",
    "p_a_k_g_l = calculate_p_a_k_g(G, node2label_l)\n",
    "print(\"P(A | k, g) for Layered Structure:\", p_a_k_g_l)\n",
    "\n",
    "# Determine which structure is more suitable\n",
    "if p_a_k_g_hs > p_a_k_g_l:\n",
    "    print(\"Hub-and-Spoke structure is more suitable for this network.\")\n",
    "else:\n",
    "    print(\"Layered structure is more suitable for this network.\")\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"---------BOGATTI AND EVERETT'S METHOD---------\")\n",
    "# Function to compute core-periphery assignments using Borgatti-Everett method\n",
    "def borgatti_everett_core_periphery(graph):\n",
    "    nodes = list(graph.nodes())\n",
    "    adjacency_matrix = nx.to_numpy_array(graph)\n",
    "    \n",
    "    # Start with random assignments of coreness (C values) for each node\n",
    "    coreness = np.random.rand(len(nodes))\n",
    "    \n",
    "    def pattern_matrix(c):\n",
    "        return np.outer(c, c)\n",
    "\n",
    "    def objective_function(c):\n",
    "        p_matrix = pattern_matrix(c)\n",
    "        correlation = np.corrcoef(adjacency_matrix[np.triu_indices(len(nodes), k=1)],\n",
    "                                  p_matrix[np.triu_indices(len(nodes), k=1)])[0, 1]\n",
    "        return -correlation  # Minimize negative correlation\n",
    "\n",
    "    # Optimize coreness values using gradient-free optimization (e.g., scipy.optimize)\n",
    "    from scipy.optimize import minimize\n",
    "    result = minimize(objective_function, coreness, bounds=[(0, 1)] * len(nodes), method=\"L-BFGS-B\")\n",
    "    \n",
    "    final_coreness = result.x\n",
    "    return dict(zip(nodes, final_coreness))\n",
    "\n",
    "# Function to calculate P(A | k, g)\n",
    "def calculate_p_a_k_g(graph, node2coreness):\n",
    "    nodes = list(graph.nodes())\n",
    "    adjacency_matrix = nx.to_numpy_array(graph)\n",
    "    pattern_matrix = np.outer(list(node2coreness.values()), list(node2coreness.values()))\n",
    "\n",
    "    m = np.sum(adjacency_matrix * pattern_matrix)\n",
    "    t = np.sum(pattern_matrix)\n",
    "\n",
    "    if t > 0:\n",
    "        return (math.factorial(int(m)) * math.factorial(int(t - m))) / math.factorial(int(t + 1))\n",
    "    return 0\n",
    "\n",
    "# Load the terrorist dataset\n",
    "G_gt = gt.collection.ns[\"terrorists_911\"]\n",
    "G = graph_tool_to_networkx(G_gt)\n",
    "\n",
    "# Apply Borgatti-Everett core-periphery method\n",
    "node2coreness = borgatti_everett_core_periphery(G)\n",
    "\n",
    "# Threshold coreness to identify core and periphery nodes\n",
    "threshold = np.median(list(node2coreness.values()))\n",
    "print(f\"Median Coreness Threshold: {threshold}\")\n",
    "core_nodes = [node for node, coreness in node2coreness.items() if coreness >= threshold]\n",
    "periphery_nodes = [node for node, coreness in node2coreness.items() if coreness < threshold]\n",
    "\n",
    "# Print results\n",
    "print(\"Node Coreness Values:\", node2coreness)\n",
    "print(\"Core Nodes:\", core_nodes)\n",
    "print(\"Periphery Nodes:\", periphery_nodes)\n",
    "\n",
    "# Calculate P(A | k, g)\n",
    "p_a_k_g = calculate_p_a_k_g(G, node2coreness)\n",
    "print(\"P(A | k, g) for Borgatti-Everett Method:\", p_a_k_g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477eb196",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
