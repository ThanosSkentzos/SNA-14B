{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f0b74bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------GALLAGHER'S METHOD---------\n",
      "Node to probabilities (HubSpoke): {0: array([0.22, 0.78]), 1: array([0.81, 0.19]), 2: array([0.2, 0.8]), 3: array([0.29, 0.71]), 4: array([0.17, 0.83]), 5: array([0.43, 0.57]), 6: array([0.33, 0.67]), 7: array([0.35, 0.65]), 8: array([0.2, 0.8]), 9: array([0.65, 0.35]), 10: array([0.27, 0.73]), 11: array([0.87, 0.13]), 12: array([0.51, 0.49]), 13: array([0.36, 0.64]), 14: array([0.19, 0.81]), 15: array([0.58, 0.42]), 16: array([0.32, 0.68]), 17: array([0.73, 0.27]), 18: array([0.26, 0.74]), 19: array([0.26, 0.74]), 20: array([0.2, 0.8]), 21: array([0.25, 0.75]), 22: array([0.38, 0.62]), 23: array([0.32, 0.68]), 24: array([0.8, 0.2]), 25: array([0.29, 0.71]), 26: array([0.38, 0.62]), 27: array([0.38, 0.62]), 28: array([0.53, 0.47]), 29: array([0.75, 0.25]), 30: array([0.71, 0.29]), 31: array([0.85, 0.15]), 32: array([0.2, 0.8]), 33: array([0.26, 0.74]), 34: array([0.37, 0.63]), 35: array([0.66, 0.34]), 36: array([0.57, 0.43]), 37: array([0.37, 0.63]), 38: array([0.61, 0.39]), 39: array([0.67, 0.33]), 40: array([0.83, 0.17]), 41: array([0.46, 0.54]), 42: array([0.39, 0.61]), 43: array([0.84, 0.16]), 44: array([0.77, 0.23]), 45: array([0.29, 0.71]), 46: array([0.25, 0.75]), 47: array([0.82, 0.18]), 48: array([0.68, 0.32]), 49: array([0.31, 0.69]), 50: array([0.38, 0.62]), 51: array([0.49, 0.51]), 52: array([0.35, 0.65]), 53: array([0.6, 0.4]), 54: array([0.24, 0.76]), 55: array([0.33, 0.67]), 56: array([0.54, 0.46]), 57: array([0.25, 0.75]), 58: array([0.2, 0.8]), 59: array([0.3, 0.7]), 60: array([0.28, 0.72]), 61: array([0.26, 0.74])}\n",
      "Core Nodes (HubSpoke): [1, 9, 11, 12, 15, 17, 24, 28, 29, 30, 31, 35, 36, 38, 39, 40, 43, 44, 47, 48, 53, 56]\n",
      "Periphery Nodes (HubSpoke): [0, 2, 3, 4, 5, 6, 7, 8, 10, 13, 14, 16, 18, 19, 20, 21, 22, 23, 25, 26, 27, 32, 33, 34, 37, 41, 42, 45, 46, 49, 50, 51, 52, 54, 55, 57, 58, 59, 60, 61]\n",
      "Node to probabilities (Layered): [[0.15 0.39 0.46]\n",
      " [0.37 0.47 0.16]\n",
      " [0.09 0.3  0.61]\n",
      " [0.12 0.31 0.57]\n",
      " [0.1  0.3  0.6 ]\n",
      " [0.11 0.38 0.51]\n",
      " [0.15 0.3  0.55]\n",
      " [0.18 0.39 0.43]\n",
      " [0.08 0.39 0.53]\n",
      " [0.3  0.44 0.26]\n",
      " [0.24 0.33 0.43]\n",
      " [0.72 0.27 0.01]\n",
      " [0.29 0.42 0.29]\n",
      " [0.24 0.44 0.32]\n",
      " [0.14 0.29 0.57]\n",
      " [0.4  0.44 0.16]\n",
      " [0.14 0.44 0.42]\n",
      " [0.33 0.49 0.18]\n",
      " [0.12 0.39 0.49]\n",
      " [0.16 0.28 0.56]\n",
      " [0.09 0.32 0.59]\n",
      " [0.17 0.28 0.55]\n",
      " [0.24 0.43 0.33]\n",
      " [0.14 0.37 0.49]\n",
      " [0.5  0.36 0.14]\n",
      " [0.16 0.3  0.54]\n",
      " [0.38 0.33 0.29]\n",
      " [0.3  0.37 0.33]\n",
      " [0.3  0.41 0.29]\n",
      " [0.58 0.25 0.17]\n",
      " [0.52 0.36 0.12]\n",
      " [0.71 0.27 0.02]\n",
      " [0.17 0.27 0.56]\n",
      " [0.11 0.31 0.58]\n",
      " [0.31 0.35 0.34]\n",
      " [0.4  0.42 0.18]\n",
      " [0.34 0.38 0.28]\n",
      " [0.28 0.35 0.37]\n",
      " [0.4  0.45 0.15]\n",
      " [0.5  0.38 0.12]\n",
      " [0.52 0.33 0.15]\n",
      " [0.36 0.39 0.25]\n",
      " [0.2  0.46 0.34]\n",
      " [0.53 0.38 0.09]\n",
      " [0.54 0.37 0.09]\n",
      " [0.19 0.29 0.52]\n",
      " [0.15 0.3  0.55]\n",
      " [0.53 0.39 0.08]\n",
      " [0.34 0.36 0.3 ]\n",
      " [0.19 0.36 0.45]\n",
      " [0.17 0.4  0.43]\n",
      " [0.2  0.5  0.3 ]\n",
      " [0.2  0.49 0.31]\n",
      " [0.35 0.34 0.31]\n",
      " [0.18 0.39 0.43]\n",
      " [0.22 0.43 0.35]\n",
      " [0.4  0.38 0.22]\n",
      " [0.24 0.34 0.42]\n",
      " [0.16 0.34 0.5 ]\n",
      " [0.2  0.38 0.42]\n",
      " [0.11 0.43 0.46]\n",
      " [0.08 0.36 0.56]]\n",
      "Number of layers detected in the Layered structure: 3\n",
      "Core Nodes (Layer 1): [11, 24, 26, 29, 30, 31, 39, 40, 43, 44, 47, 53, 56]\n",
      "Periphery Nodes (Layer 2): [1, 9, 12, 13, 15, 16, 17, 22, 27, 28, 34, 35, 36, 38, 41, 42, 48, 51, 52, 55]\n",
      "Periphery Nodes (Layer 3): [0, 2, 3, 4, 5, 6, 7, 8, 10, 14, 18, 19, 20, 21, 23, 25, 32, 33, 37, 45, 46, 49, 50, 54, 57, 58, 59, 60, 61]\n",
      "P(A | k, g) for Hub-and-Spoke Structure: 1.978464509496601e-93\n",
      "P(A | k, g) for Layered Structure: 5.13823523835023e-70\n",
      "Layered structure is more suitable for this network.\n",
      "----------------------------------------------\n",
      "---------BOGATTI AND EVERETT'S METHOD---------\n",
      "Median Coreness Threshold: 0.035541958078633765\n",
      "Node Coreness Values: {0: 0.0, 1: 0.07529527503204189, 2: 0.0, 3: 0.0, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.0, 8: 0.0, 9: 0.0, 10: 0.0, 11: 1.0, 12: 0.0, 13: 0.12836529203823335, 14: 0.0, 15: 0.12836533517686607, 16: 0.0, 17: 0.0, 18: 0.0, 19: 0.0, 20: 0.0, 21: 0.0, 22: 0.0, 23: 0.0, 24: 0.46144592370205034, 25: 0.048282837807075464, 26: 0.30257851516924417, 27: 0.29670745335388793, 28: 0.357989720131509, 29: 0.45394673377893835, 30: 0.49700492948607883, 31: 0.9723225248103659, 32: 0.07529333084376424, 33: 0.07529327991920147, 34: 0.2715519819739259, 35: 0.4105409397286308, 36: 0.2968599208474718, 37: 0.24124642989201567, 38: 0.3771719437597233, 39: 0.3805722866993796, 40: 0.4769478953652595, 41: 0.30697275941187707, 42: 0.1497834610845104, 43: 0.45087984495913025, 44: 0.19685286740120456, 45: 0.022801078350192072, 46: 0.0, 47: 0.29422970416553995, 48: 0.130471830615882, 49: 0.009072294239912283, 50: 0.02118855823787413, 51: 0.1182447034773818, 52: 0.05179077742821558, 53: 0.01902870532921258, 54: 0.0005810859756879138, 55: 0.07753201743348562, 56: 0.07753313838611725, 57: 0.018420636577657988, 58: 0.01842504953419842, 59: 0.0, 60: 0.0, 61: 0.0}\n",
      "Core Nodes: [1, 11, 13, 15, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 47, 48, 51, 52, 55, 56]\n",
      "Periphery Nodes: [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 14, 16, 17, 18, 19, 20, 21, 22, 23, 45, 46, 49, 50, 53, 54, 57, 58, 59, 60, 61]\n",
      "P(A | k, g) for Borgatti-Everett Method: 1.0735429283154858e-28\n"
     ]
    }
   ],
   "source": [
    "import graph_tool.all as gt\n",
    "import networkx as nx\n",
    "import sys\n",
    "from itertools import combinations\n",
    "import math\n",
    "import numpy as np\n",
    "from core_periphery_sbm import core_periphery as cp\n",
    "\n",
    "sys.path.append(\"/root/core_periphery_sbm\")\n",
    "\n",
    "# Convert a graph-tool graph to a NetworkX graph\n",
    "def graph_tool_to_networkx(gt_graph):\n",
    "    nx_graph = nx.Graph() if not gt_graph.is_directed() else nx.DiGraph()\n",
    "\n",
    "    # Add nodes\n",
    "    for v in gt_graph.vertices():\n",
    "        nx_graph.add_node(int(v))\n",
    "\n",
    "    # Add edges\n",
    "    for e in gt_graph.edges():\n",
    "        nx_graph.add_edge(int(e.source()), int(e.target()))\n",
    "\n",
    "    return nx_graph\n",
    "\n",
    "# Load Les Mis graph from NetworkX\n",
    "G = graph_tool_to_networkx(gt.collection.ns[\"terrorists_911\"])\n",
    "\n",
    "print(\"---------GALLAGHER'S METHOD---------\")\n",
    "# Initialize and infer Hub-and-Spoke model\n",
    "hubspoke = cp.HubSpokeCorePeriphery(n_gibbs=100, n_mcmc=100)  # Using a fixed number of MCMC steps for the whole graph\n",
    "hubspoke.infer(G)\n",
    "\n",
    "# Initialize and infer Layered model\n",
    "layered = cp.LayeredCorePeriphery(n_layers=3, n_gibbs=100, n_mcmc=100)  # Using a fixed number of MCMC steps for the whole graph\n",
    "layered.infer(G)\n",
    "\n",
    "# Get node-to-group assignments for both models\n",
    "node2label_hs = hubspoke.get_labels(prob=False, return_dict=True)\n",
    "node2label_l = layered.get_labels(prob=False, return_dict=True)\n",
    "\n",
    "# Calculate P(A | k, g)\n",
    "def calculate_p_a_k_g(graph, node2label):\n",
    "    \"\"\"\n",
    "    Calculate P(A | k, g) for a graph and node-to-layer mapping.\n",
    "\n",
    "    Args:\n",
    "        graph (nx.Graph): The input graph (NetworkX format).\n",
    "        node2label (dict): Mapping of nodes to their layer assignments.\n",
    "\n",
    "    Returns:\n",
    "        float: The value of P(A | k, g).\n",
    "    \"\"\"\n",
    "    # Number of layers (k)\n",
    "    k = len(set(node2label.values()))\n",
    "\n",
    "    # Initialize m_r and t_r for each group\n",
    "    m = [0] * k  # Number of edges within each group\n",
    "    t = [0] * k  # Number of possible pairs within each group\n",
    "\n",
    "    # Reverse the node-to-layer mapping to group nodes by layers\n",
    "    layer_to_nodes = {r: [] for r in range(k)}\n",
    "    for node, layer in node2label.items():\n",
    "        layer_to_nodes[layer].append(node)\n",
    "\n",
    "    # Calculate m_r and t_r for each group\n",
    "    for r in range(k):\n",
    "        nodes_in_layer = layer_to_nodes[r]\n",
    "        if len(nodes_in_layer) < 2:\n",
    "            continue  # Skip groups with fewer than 2 nodes\n",
    "\n",
    "        # Count edges within the group\n",
    "        m[r] = sum(1 for u, v in combinations(nodes_in_layer, 2) if graph.has_edge(u, v))\n",
    "\n",
    "        # Count total possible pairs within the group\n",
    "        t[r] = len(nodes_in_layer) * (len(nodes_in_layer) - 1) // 2\n",
    "\n",
    "    # Calculate P(A | k, g) using the formula\n",
    "    p_a_k_g = 1.0\n",
    "    for r in range(k):\n",
    "        if t[r] > 0:  # Avoid division by zero for empty groups\n",
    "            p_a_k_g *= (math.factorial(m[r]) * math.factorial(t[r] - m[r])) / math.factorial(t[r] + 1)\n",
    "\n",
    "    return p_a_k_g\n",
    "\n",
    "# Print probabilities for Hub-and-Spoke model\n",
    "node2probs_hs = hubspoke.get_labels(prob=True, return_dict=True)\n",
    "print(\"Node to probabilities (HubSpoke):\", node2probs_hs)\n",
    "\n",
    "# Print core and periphery nodes for Hub-and-Spoke model\n",
    "core_nodes_hs = [node for node, group in node2label_hs.items() if group == 0]  # Assuming core is group 0\n",
    "periphery_nodes_hs = [node for node, group in node2label_hs.items() if group != 0]\n",
    "print(\"Core Nodes (HubSpoke):\", core_nodes_hs)\n",
    "print(\"Periphery Nodes (HubSpoke):\", periphery_nodes_hs)\n",
    "\n",
    "# Print probabilities for Layered model\n",
    "node2probs_l = layered.get_labels(prob=True, return_dict=False)\n",
    "print(\"Node to probabilities (Layered):\", node2probs_l)\n",
    "\n",
    "# Count and print number of layers detected in the Layered model\n",
    "num_layers = len(set(node2label_l.values()))\n",
    "print(f\"Number of layers detected in the Layered structure: {num_layers}\")\n",
    "\n",
    "# Identify core and periphery nodes in the Layered model\n",
    "layer_to_nodes = {layer: [] for layer in range(num_layers)}\n",
    "for node, layer in node2label_l.items():\n",
    "    layer_to_nodes[layer].append(node)\n",
    "\n",
    "# Print core and periphery nodes for Layered model with layer numbers\n",
    "for layer, nodes in layer_to_nodes.items():\n",
    "    if layer == 0:\n",
    "        print(f\"Core Nodes (Layer {layer + 1}):\", nodes)\n",
    "    else:\n",
    "        print(f\"Periphery Nodes (Layer {layer + 1}):\", nodes)\n",
    "\n",
    "# Calculate P(A | k, g) for Hub-and-Spoke structure\n",
    "p_a_k_g_hs = calculate_p_a_k_g(G, node2label_hs)\n",
    "print(\"P(A | k, g) for Hub-and-Spoke Structure:\", p_a_k_g_hs)\n",
    "\n",
    "# Calculate P(A | k, g) for Layered structure\n",
    "p_a_k_g_l = calculate_p_a_k_g(G, node2label_l)\n",
    "print(\"P(A | k, g) for Layered Structure:\", p_a_k_g_l)\n",
    "\n",
    "# Determine which structure is more suitable\n",
    "if p_a_k_g_hs > p_a_k_g_l:\n",
    "    print(\"Hub-and-Spoke structure is more suitable for this network.\")\n",
    "else:\n",
    "    print(\"Layered structure is more suitable for this network.\")\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"---------BOGATTI AND EVERETT'S METHOD---------\")\n",
    "# Function to compute core-periphery assignments using Borgatti-Everett method\n",
    "def borgatti_everett_core_periphery(graph):\n",
    "    nodes = list(graph.nodes())\n",
    "    adjacency_matrix = nx.to_numpy_array(graph)\n",
    "    \n",
    "    # Start with random assignments of coreness (C values) for each node\n",
    "    coreness = np.random.rand(len(nodes))\n",
    "    \n",
    "    def pattern_matrix(c):\n",
    "        return np.outer(c, c)\n",
    "\n",
    "    def objective_function(c):\n",
    "        p_matrix = pattern_matrix(c)\n",
    "        correlation = np.corrcoef(adjacency_matrix[np.triu_indices(len(nodes), k=1)],\n",
    "                                  p_matrix[np.triu_indices(len(nodes), k=1)])[0, 1]\n",
    "        return -correlation  # Minimize negative correlation\n",
    "\n",
    "    # Optimize coreness values using gradient-free optimization (e.g., scipy.optimize)\n",
    "    from scipy.optimize import minimize\n",
    "    result = minimize(objective_function, coreness, bounds=[(0, 1)] * len(nodes), method=\"L-BFGS-B\")\n",
    "    \n",
    "    final_coreness = result.x\n",
    "    return dict(zip(nodes, final_coreness))\n",
    "\n",
    "# Function to calculate P(A | k, g)\n",
    "def calculate_p_a_k_g(graph, node2coreness):\n",
    "    nodes = list(graph.nodes())\n",
    "    adjacency_matrix = nx.to_numpy_array(graph)\n",
    "    pattern_matrix = np.outer(list(node2coreness.values()), list(node2coreness.values()))\n",
    "\n",
    "    m = np.sum(adjacency_matrix * pattern_matrix)\n",
    "    t = np.sum(pattern_matrix)\n",
    "\n",
    "    if t > 0:\n",
    "        return (math.factorial(int(m)) * math.factorial(int(t - m))) / math.factorial(int(t + 1))\n",
    "    return 0\n",
    "\n",
    "# Load the terrorist dataset\n",
    "G_gt = gt.collection.ns[\"terrorists_911\"]\n",
    "G = graph_tool_to_networkx(G_gt)\n",
    "\n",
    "# Apply Borgatti-Everett core-periphery method\n",
    "node2coreness = borgatti_everett_core_periphery(G)\n",
    "\n",
    "# Threshold coreness to identify core and periphery nodes\n",
    "threshold = np.median(list(node2coreness.values()))\n",
    "print(f\"Median Coreness Threshold: {threshold}\")\n",
    "core_nodes = [node for node, coreness in node2coreness.items() if coreness >= threshold]\n",
    "periphery_nodes = [node for node, coreness in node2coreness.items() if coreness < threshold]\n",
    "\n",
    "# Print results\n",
    "print(\"Node Coreness Values:\", node2coreness)\n",
    "print(\"Core Nodes:\", core_nodes)\n",
    "print(\"Periphery Nodes:\", periphery_nodes)\n",
    "\n",
    "# Calculate P(A | k, g)\n",
    "p_a_k_g = calculate_p_a_k_g(G, node2coreness)\n",
    "print(\"P(A | k, g) for Borgatti-Everett Method:\", p_a_k_g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477eb196",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
